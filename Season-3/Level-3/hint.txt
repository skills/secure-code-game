At the end of the day, system prompt and user prompt are just two different
parts of the same prompt that is fed to the LLM. You can try to exploit that by pretending that the system prompt did
not yet end, and you are continuing it. This is a common trick in prompt engineering.
Think how output filtering may be implemented - maybe you can bypass denylists by instructing the LLM to change the output
a bit, so it does not match the denylist. You can also try to mix languages, as the model might not be able to detect
that you are using a different language in the prompt.
